%!TEX root = paper.tex

\section{System Architecture}

In this section we lay out the architecture of Flink as a software stack, and as a distributed system. While Flink's stack of APIs continues to grow, we can distinguish four main layers: deployment, core, APIs, and libraries.

\para{Flink's Runtime and APIS.} The core of Flink is the distributed dataflow engine, which executes dataflow programs. A Flink runtime program is a DAG of stateful operators connected with data streams. There are two core APIs in Flink: the DataSet API for processing finite data sets (often referred to as “batch processing”), and the DataStream API for processing potentially unbounded data streams (often referred to as “stream processing”). Flink’s core runtime engine can be seen as a streaming dataflow engine, and both the DataSet and DataStream APIs create runtime programs executable by the engine. As such, it serves as the common fabric to abstract both bounded (batch) and unbounded (stream) processing. On top of the core APIs, Flink bundles domain-specific libraries and APIs that generate DataSet and DataStream API programs (currently FlinkML, Gelly, and Table). 

A Flink cluster comprises of three types of processes: the client, the JobManager (JM - master), and one or more TaskManagers (RM - workers). The client takes the program code, transforms it to a runtime executable, and submits it to the JobManager. The compilation process involves a type extraction and checking phase that generates serializers and comparators for all used types. DataSet programs, also go through a cost-based query optimization phase, similar to the physical optimizations performed by relational query optimizers (more details in ???).

The JobManager is Flink’s master node. It coordinates all message-passing during job execution by sending heartbeats to the TaskManagers and receiving statistics, controls the tasks’ lifecycle, and coordinates checkpointing used for recovery. The actual data processing takes place in the TaskManagers that they execute several tasks in multiple threads, and maintain data structures shared by all tasks (e.g., buffer pools) executed by a TM. TMs communicate directly with each other using a multiplexed TCP connection per TM pair. 




\begin{figure}
\centering
\begin{minipage}{.52\textwidth}
\centering
	\includegraphics[width=.9\textwidth]{figs/architecture.pdf}
    \caption{Flink's Process Model.}
    \label{fig:process-model}
\end{minipage}%
\begin{minipage}{0.52\textwidth}
\centering
\includegraphics[width=.8\textwidth]{figs/stack.pdf}
\label{fig:FlinkStack}
\caption{Flink's Software Stack.}
\end{minipage}
\end{figure}




