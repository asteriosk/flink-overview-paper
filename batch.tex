%!TEX root = paper.tex

\section{Batch analytics on top of dataflows}
\label{sec:batch}

A bounded data set is a special case of an unbounded data stream. Thus, a streaming program that inserts all of its input data in a window can form a “batch” program and “batch processing” should be fully covered by Flink’s features that we presented above. However, i) the syntax, i.e., the API for batch computation can be simplified (e.g., there is not need for artificial global window definitions, simpler join syntax), and iii) programs that process bounded data sets are amenable to additional optimizations, more efficient book keeping for fault tolerance, and staged scheduling.

\vspace{2mm}
\noindent Flink approaches batch processing as follows:\vspace{-3mm}
\begin{itemize}
	\item Batch computations are executed by the same runtime as streaming computations. The runtime executable may be parameterized with blocked data streams to break up large computations in isolated stages that are scheduled successively. \vspace{-3mm}
	\item Periodic snapshotting is turned off when its overhead is high. Instead, fault recovery can be achieved by replaying the lost stream partitions from the latest materialized intermediate stream (possibly the source).\vspace{-3mm}
	\item Blocking operators (e.g., joins and sorts) are simply operator implementations that happen to block until they have consumed their entire input. The runtime is not aware of whether an operator is blocking or not. These operators use managed memory provided by Flink (either on- or off- the JVM heap), and can spill to disk if their inputs exceed their memory bounds.\vspace{-3mm}
	\item A dedicated DataSet API provides familiar abstractions for batch computations, namely a bounded fault-tolerant DataSet data structure, and transformations on DataSets (e.g., joins, aggregations, iterations, etc).\vspace{-3mm}
	\item A query optimization layer transforms a DataSet program to an efficient executable.\vspace{-3mm}
\end{itemize}



\subsection{Query Optimization} 


Flink’s optimizer builds on techniques from parallel database systems such as plan equivalence, cost modeling and interesting property propagation. However, the arbitrary UDF-heavy DAGs that make up Flink’s dataflow programs do not allow a traditional optimizer to employ database techniques out of the box \cite{blackBoxes}, since the operators hide their semantics from the optimizer. For the same reason, cardinality and cost estimation methods are equally difficult to employ. Flink’s runtime supports various execution strategies including repartition/broadcast data transfer, as well as sort-based grouping and sort- and hash-based join implementations. Flink’s optimizer enumerates different physical plans based on the concept of interesting properties propagation \cite{scopeOptimizer}, using a cost-based approach to choose among multiple physical plans. The cost includes network/disk I/O and CPU cost. To overcome the cardinality estimation issues that were mentioned earlier,  Flink’s optimizer uses hints that are provided by the programmer.


\subsection{Memory Management} Building on database technology, Flink, instead of allocating objects in the JVM’s heap to represent buffered in-flight data records, serializes data into a  memory segments. Operations such as sorting and joining operate as much as possible on the binary data directly, keeping the de/serialization overhead at a minimum and partially spilling data to disk when needed. To handle arbitrary objects, Flink uses type inference, and  custom serialization mechanisms.  By keeping the data processing on binary representation and off-heap, Flink manages to reduce the garbage collection overhead, and use cache-efficient and robust algorithms [Graefe join paper] that scale gracefully under memory pressure.

\subsection{Batch Iterations on top of Dataflows}
\label{sec:batch-iterations}
Most batch dataflow approaches execute iterations by submitting a new job for each iteration or by adding additional nodes to a running DAG \cite{DBLP:journals/pvldb/BuHBE10, DBLP:conf/hotcloud/ZahariaCFSS10}. Flink keeps the DAG-based runtime and scheduler, and allows for special ``head'' and ``tail'' tasks that are connected with feedback edges, to signify the beginning and end of each iteration. Flink's iterations are competitive with specialized graph engines \cite{DBLP:journals/pvldb/EwenTKM12}. This is achieved through the concept of  \emph{delta} iterations, which exploit sparse computational dependencies, and are used as the basis for Gelly, Flink's Graph API. Finally, Flink offers Bulk Synchronous Parallel (BSP) as well as Stale Synchronous Parallel (SSP) iterations in its DataSet API.


