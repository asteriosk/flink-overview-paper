%!TEX root = paper.tex

\section{Batch analytics on top of dataflows}
\label{sec:batch}

A bounded data set is a special case of an unbounded data stream. Thus, a streaming program that inserts all of its input data in a window can form a “batch” program and “batch processing” should be fully covered by Flink’s features that we presented above. However, i) the syntax, i.e., the API for batch computation can be simplified (e.g., there is not need for artificial global window definitions, simpler join syntax), and iii) programs that process bounded data sets are amenable to additional optimizations, more efficient book keeping for fault tolerance, and staged scheduling.

\vspace{2mm}
\noindent Flink approaches batch processing as follows:\vspace{-3mm}
\begin{itemize}
	\item Batch computations are executed by the same runtime as streaming computations. The runtime executable may be parameterized with blocked data streams to break up large computations in isolated stages that are scheduled successively. \vspace{-3mm}
	\item Periodic snapshotting is turned off when its overhead is high. Instead, fault recovery can be achieved by replaying the lost stream partitions from the latest materialized intermediate stream (possibly the source).\vspace{-3mm}
	\item Blocking operators (e.g., joins and sorts) are simply operator implementations that happen to block until they have consumed their entire input. The runtime is not aware of whether an operator is blocking or not. These operators use managed memory provided by Flink (either on- or off- the JVM heap), and can spill to disk if their inputs exceed their memory bounds.\vspace{-3mm}
	\item A dedicated DataSet API provides familiar abstractions for batch computations, namely a bounded fault-tolerant DataSet data structure, and transformations on DataSets (e.g., joins, aggregations, iterations, etc).\vspace{-3mm}
	\item A query optimization layer transforms a DataSet program to an efficient executable.\vspace{-3mm}
\end{itemize}

\subsection{Query Optimization} 
Flink’s optimizer builds on techniques from parallel database systems such as plan equivalence, cost modeling and interesting property propagation. However, the arbitrary UDF-heavy DAGs that make up Flink’s dataflow programs do not allow a traditional optimizer to employ database techniques out of the box \cite{blackBoxes}, since the operators hide their semantics from the optimizer. For the same reason, cardinality and cost estimation methods are equally difficult to employ. Flink’s runtime supports various execution strategies including repartition/broadcast data transfer, as well as sort-based grouping and sort- and hash-based join implementations. Flink’s optimizer enumerates different physical plans based on the concept of interesting properties propagation \cite{scopeOptimizer}, using a cost-based approach to choose among multiple physical plans. The cost includes network/disk I/O and CPU cost. To overcome the cardinality estimation issues that were mentioned earlier,  Flink’s optimizer uses hints that are provided by the programmer.

\subsection{Memory Management} Building on database technology, Flink, instead of allocating objects in the JVM’s heap to represent buffered in-flight data records, serializes data into a  memory segments. Operations such as sorting and joining operate as much as possible on the binary data directly, keeping the de/serialization overhead at a minimum and partially spilling data to disk when needed. To handle arbitrary objects, Flink uses type inference, and  custom serialization mechanisms.  By keeping the data processing on binary representation and off-heap, Flink manages to reduce the garbage collection overhead, and use cache-efficient and robust algorithms [Graefe join paper] that scale gracefully under memory pressure.

\subsection{Batch Iterations on top of Dataflows}
\label{sec:batch-iterations}
Iterative graph analytics, parallel gradient descent and optimisation techniques have been implemented in the past on top of Bulk Synchronous Parallel (BSP) and Stale Synchronous Parallel (SSP) models, among others. The Flink execution model, allows for any type of structured iteration logic to be implemented on top, by using iteration control events. For instance, in the case of a BSP execution, iteration control events mark the beginning and the end of supersteps in an iterative computation. Finally, Flink introduces further novel optimisation techniques such as the concept of \emph{delta} iterations \cite{DBLP:journals/pvldb/EwenTKM12}, which can exploit sparse computational dependencies (already part of Gelly, Flink's Graph API).  

